\chapter{Evaluation of the Best Classification Method}
\label{chapter_classification}
\section{Considered classification methods}
\label{sec_considered_classif}

\section{Classification based on the fundamental frequency}
\label{sec_intuitive_approach}
Based on the exploratory data analysis described in Chapter~\ref{chapter_data_exploration}, we propose to perform the classification based on the ``meanfun'' feature alone. 
This will give a baseline for further analysis described in the remaining of this Chapter.

To perform the analysis, we randomly split the dataset into a training set~( \SI{80}{\percent}) and a test set~(\SI{20}{\percent}). The training set is used to fit the models and for best parameter selection if needed. The test set is used to compute the classification error and to compare the models. The classification error considered in the study is the $0-1$ loss.
 
\section{The naive strategy}
\label{sec_naive_strat}
\subsection{Description}
\subsection{Results}
\begin{table}[htb]
	\ra{1.2}
	\caption{Classification Error of the Methods for Different Seed Numbers}
	\begin{center}
		\begin{tabular}{@{} c c c  c c c c @{}}\toprule
			\multirow{2}{*}{Type} & \multirow{2}{*}{Methods} &  \multicolumn{5}{c}{Seed number}\\
			& & 1 & 2 & 3 & 4 & 5 \\
			\midrule
			\multirow{5}{*}{Max. Likelihood} & Logistic reg. & \num{0.0158} & \num{0.0347} & \num{0.0315} & \num{0.0237} & \num{0.0221} \\
			& Logistic reg. - Ridge & \num{0.0158} & \num{0.0315} & \num{0.0315} & \num{0.0189} & \num{0.0284} \\
			& Logistic reg. - Lasso & \num{0.0315} & \num{0.0363} & \num{0.0379} & \num{0.0284} & \num{0.0300} \\
			& LDA & \num{0.0315} & \num{0.0410} & \num{0.0379} & \num{0.0284} & \num{0.0268} \\
			& QDA & \num{0.0347} & \num{0.0347} & \num{0.0347} & \num{0.0268} & \num{0.0363} \\
			\cmidrule{1-7}
			\multirow{5}{*}{Trees} & Tree & \num{0.0379} & \num{0.0426} & \num{0.0315} & \num{0.0284} & \num{0.0300}\\
			& Pruned Tree & \num{0.0394} & \num{0.0473} & \num{0.0347} & \num{0.0363} & \num{0.0300}\\  
			& Bagging & \num{0.0237} & \num{0.0410} & \num{0.0142} & \textbf{\num{0.0174}} & \num{0.0284}\\
			& Random Forest & \num{0.0189} & \num{0.0347} & \textbf{\num{0.0126}} & \num{0.0205} & \num{0.0205}\\
			& XGBoost & \num{0.0189} & \textbf{\num{0.0268}} & \textbf{\num{0.0126}} & \num{0.0205} & \textbf{\num{0.0189}}\\
			\cmidrule{1-7}
			\multirow{2}{*}{SVM} & Linear & \textbf{\num{0.0142}} & \num{0.0315} & \num{0.0284} & \num{0.0189} & \num{0.0252}\\
			& Gaussian & \num{0.0205} & \num{0.0284} & \num{0.0126} & \num{0.0189} & \num{0.0221}\\
			\cmidrule{1-7}
			x & kNN & \num{0.0300} & \num{0.0347} & \num{0.0252} & \num{0.0379} & \num{0.0300}\\
			\bottomrule
			\end{tabular}
			\end{center}
			\label{tab_res_naive}
\end{table}

\begin{table}[htb]
	\ra{1.2}
	\caption{Classification Error of the Methods for Different Seed Numbers with $50/50$ split}
	\begin{center}
		\begin{tabular}{@{} c c c  c c c c @{}}\toprule
			\multirow{2}{*}{Type} & \multirow{2}{*}{Methods} &  \multicolumn{5}{c}{Seed number}\\
			& & 1 & 2 & 3 & 4 & 5 \\
			\midrule
			\multirow{5}{*}{Max. Likelihood} & Logistic reg. & \num{0.0158} & \num{0.0347} & \num{0.0315} & \num{0.0237} & \num{0.0221} \\
			& Logistic reg. - Ridge & \num{0.0158} & \num{0.0315} & \num{0.0315} & \num{0.0189} & \num{0.0284} \\
			& Logistic reg. - Lasso & \num{0.0315} & \num{0.0363} & \num{0.0379} & \num{0.0284} & \num{0.0300} \\
			& LDA & \num{0.0315} & \num{0.0410} & \num{0.0379} & \num{0.0284} & \num{0.0268} \\
			& QDA & \num{0.0347} & \num{0.0347} & \num{0.0347} & \num{0.0268} & \num{0.0363} \\
			\cmidrule{1-7}
			\multirow{5}{*}{Trees} & Tree & \num{0.0379} & \num{0.0426} & \num{0.0315} & \num{0.0284} & \num{0.0300}\\
			& Pruned Tree & \num{0.0394} & \num{0.0473} & \num{0.0347} & \num{0.0363} & \num{0.0300}\\  
			& Bagging & \num{0.0237} & \num{0.0410} & \num{0.0142} & \textbf{\num{0.0174}} & \num{0.0284}\\
			& Random Forest & \num{0.0189} & \num{0.0347} & \textbf{\num{0.0126}} & \num{0.0205} & \num{0.0205}\\
			& XGBoost & \num{0.0189} & \textbf{\num{0.0268}} & \textbf{\num{0.0126}} & \num{0.0205} & \textbf{\num{0.0189}}\\
			\cmidrule{1-7}
			\multirow{2}{*}{SVM} & Linear & \textbf{\num{0.0142}} & \num{0.0315} & \num{0.0284} & \num{0.0189} & \num{0.0252}\\
			& Gaussian & \num{0.0205} & \num{0.0284} & \num{0.0126} & \num{0.0189} & \num{0.0221}\\
			\cmidrule{1-7}
			x & kNN & \num{0.0300} & \num{0.0347} & \num{0.0252} & \num{0.0379} & \num{0.0300}\\
			\bottomrule
		\end{tabular}
	\end{center}
	\label{tab_res_our_strategy}
\end{table}